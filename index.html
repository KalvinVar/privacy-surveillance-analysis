<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Digital Privacy & Surveillance | A Sociological Analysis</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Playfair+Display:wght@600;700&display=swap" rel="stylesheet">
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar">
        <div class="container">
            <div class="nav-brand">Digital Privacy Watch</div>
            <ul class="nav-menu">
                <li><a href="#home" class="nav-link active">Home</a></li>
                <li><a href="#problem" class="nav-link">The Problem</a></li>
                <li><a href="#solutions" class="nav-link">Solutions</a></li>
                <li><a href="#action" class="nav-link">Take Action</a></li>
                <li><a href="#resources" class="nav-link">Resources</a></li>
            </ul>
        </div>
    </nav>

    <!-- Hero Section -->
    <section id="home" class="hero">
        <div class="hero-overlay"></div>
        <div class="hero-content">
            <h1 class="hero-title">Privacy, Consent, and Surveillance</h1>
            <p class="hero-subtitle">A Sociological Analysis of Digital Rights in the Age of Surveillance Capitalism</p>
            <div class="hero-stats">
                <div class="stat-box">
                    <div class="stat-number">72%</div>
                    <div class="stat-label">Heard of GDPR privacy rights</div>
                </div>
                <div class="stat-box">
                    <div class="stat-number">60%</div>
                    <div class="stat-label">Low-income households lack privacy tools</div>
                </div>
                <div class="stat-box">
                    <div class="stat-number">34.7%</div>
                    <div class="stat-label">Facial recognition error rate for dark-skinned women</div>
                </div>
            </div>
            <a href="#problem" class="cta-button">Explore the Issue</a>
        </div>
    </section>

    <!-- Problem Section -->
    <section id="problem" class="section">
        <div class="container">
            <h2 class="section-title">Understanding the Problem</h2>
            <p class="section-intro">From what I've seen, digital privacy and surveillance have become one of the biggest sociological issues we're facing right now. Every time we go online, we're basically feeding into what researchers call <strong>surveillance capitalism</strong>, a system where companies collect our personal data, analyze it, and turn it into profit (Zuboff, 2019). The problem is that this creates a huge power imbalance. Big tech companies and governments know everything about us, but we barely know what they're doing with our information. And that's not just annoying. It actually threatens our freedom and how democracy works (Cinnamon, 2017).</p>

            <!-- Theoretical Perspectives -->
            <div class="perspectives-grid">
                <div class="perspective-card conflict">
                    <div class="icon">‚öñÔ∏è</div>
                    <h3>Conflict Theory</h3>
                    <p>When you look at surveillance through conflict theory, it's pretty clear that there's a power struggle going on. Tech giants are basically hoarding our personal data and turning it into profit, while most of us have no real control over what happens to our information (Cinnamon, 2017). They know everything about us (what we search for, who we talk to, where we go) but we know almost nothing about what they're actually doing with all that data (Zuboff, 2015). That imbalance is what creates inequality in the digital world.</p>
                </div>
                <div class="perspective-card functional">
                    <div class="icon">üîÑ</div>
                    <h3>Structural Functionalism</h3>
                    <p>I know data collection can serve some useful purposes ‚Äî like keeping us safe or making apps more personalized. But there's a point where it crosses a line and becomes dysfunctional. When surveillance gets so invasive that people stop trusting institutions, or when it makes people scared to speak freely online, that's a breakdown of the social contract. The Snowden revelations showed us just how far that breakdown had gone (Privacy and Civil Liberties Oversight Board, 2014).</p>
                </div>
                <div class="perspective-card symbolic">
                    <div class="icon">üí¨</div>
                    <h3>Symbolic Interactionism</h3>
                    <p>Privacy and consent aren't just technical issues ‚Äî they're social concepts that have completely changed in the digital age. I've noticed how websites and apps use what are called "dark patterns" ‚Äî basically design tricks that manipulate you into sharing more information than you actually want to. It's not always obvious, but these patterns shape how we think about giving consent and what our relationship with technology should look like (Richards & Hartzog, 2019).</p>
                </div>
            </div>

            <!-- Impact on Communities -->
            <div class="impact-section">
                <h3 class="subsection-title">Disproportionate Impact on Marginalized Communities</h3>
                
                <div class="impact-cards">
                    <div class="impact-card">
                        <div class="impact-header">
                            <span class="impact-icon">üë•</span>
                            <h4>Racial & Ethnic Minorities</h4>
                        </div>
                        <ul class="impact-list">
                            <li>Facial recognition tech has some serious problems when it comes to accuracy. Studies show error rates as high as 34.7% for darker-skinned women, compared to less than 1% for lighter-skinned men (Buolamwini & Gebru, 2018). That's a huge gap, and it can lead to real harm.</li>
                            <li>Predictive policing algorithms keep reinforcing the same discriminatory patterns we see in law enforcement, making things worse for communities of color</li>
                            <li>Data brokers are selling location information from mobile apps to agencies like ICE, letting them track undocumented immigrants without even needing a warrant (Biddle, 2020)</li>
                        </ul>
                    </div>

                    <div class="impact-card">
                        <div class="impact-header">
                            <span class="impact-icon">üí∞</span>
                            <h4>Low-Income Populations</h4>
                        </div>
                        <ul class="impact-list">
                            <li>There's basically a two-tiered system now: people with money can pay for privacy, while everyone else has to use "free" services that collect their data. Most households earning under $20,000 annually know about the privacy risks but can't afford the tools to protect themselves (Madden, 2017). That's not fair.</li>
                            <li>Low-wage workers face way more surveillance than higher-paid employees ‚Äî things like keystroke monitoring and facial recognition at work. Meanwhile, people in higher-income jobs get to keep more of their privacy (Eubanks, 2018)</li>
                            <li>People with lower incomes end up in what researchers call a "privacy-poor, surveillance-rich" situation, even though they're just as aware of the risks as everyone else (Gangadharan, 2017)</li>
                        </ul>
                    </div>

                    <div class="impact-card">
                        <div class="impact-header">
                            <span class="impact-icon">üè≥Ô∏è‚Äçüåà</span>
                            <h4>Women & LGBTQ+ Individuals</h4>
                        </div>
                        <ul class="impact-list">
                            <li>After the Dobbs decision, reproductive health app data can actually be used against people seeking abortions. This hits low-income women the hardest since they often can't afford to travel to states where it's legal</li>
                            <li>Dating apps collect really sensitive information about people's sexual orientation, which can be dangerous for LGBTQ+ folks, especially in places where being out isn't safe</li>
                            <li>Stalkerware tools are mostly used to track and control women in abusive relationships, letting abusers monitor them even when they're not physically together</li>
                        </ul>
                    </div>
                </div>
            </div>

            <!-- Controversies -->
            <div class="controversies-section">
                <h3 class="subsection-title">Relevant Controversies</h3>
                <div class="controversy-grid">
                    <div class="controversy-card">
                        <h4>"Nothing to Hide" Argument</h4>
                        <div class="argument-pro">
                            <strong>The Claim:</strong> If you have "nothing to hide," surveillance shouldn't matter.
                        </div>
                        <div class="argument-con">
                            <strong>The Counter:</strong>
                            <ul>
                                <li>Privacy is a basic human right. It shouldn't matter whether you've "done something wrong" or not</li>
                                <li>This argument completely ignores how marginalized communities get surveilled way more than others, without getting the same protections</li>
                                <li>It assumes people in power will always do the right thing ‚Äî and history shows us that's definitely not true</li>
                            </ul>
                        </div>
                    </div>

                    <div class="controversy-card">
                        <h4>Security vs. Privacy</h4>
                        <div class="argument-pro">
                            <strong>The Claim:</strong> Mass surveillance is necessary for preventing terrorism and ensuring national security.
                        </div>
                        <div class="argument-con">
                            <strong>The Counter:</strong>
                            <ul>
                                <li>The NSA's bulk phone records program didn't actually prevent attacks very effectively (Privacy and Civil Liberties Oversight Board, 2014). Targeted surveillance with warrants works better anyway</li>
                                <li>We don't have to choose between security and privacy ‚Äî that's a false choice</li>
                                <li>You can have good security without violating everyone's privacy rights</li>
                            </ul>
                        </div>
                    </div>

                    <div class="controversy-card">
                        <h4>Tech Industry Defense</h4>
                        <div class="argument-pro">
                            <strong>The Claim:</strong> Data collection benefits users through personalization and enables "free" services.
                        </div>
                        <div class="argument-con">
                            <strong>The Counter:</strong>
                            <ul>
                                <li>Most Americans don't actually understand what they're consenting to. Research shows people lack the basic knowledge to make informed choices about their data (Turow et al., 2023). So individual consent doesn't really work at this scale</li>
                                <li>The way consent works online is broken. It's either unwitting (you don't know what you agreed to), coerced (agree or you can't use the service), or incapacitated (you literally can't understand the terms) (Richards & Hartzog, 2019)</li>
                                <li>The whole business model of surveillance capitalism goes against meaningful consent. It's not a fair trade</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Solutions Section -->
    <section id="solutions" class="section solutions-section">
        <div class="container">
            <h2 class="section-title">Current Strategies Addressing the Problem</h2>
            <p class="section-intro">Right now, there are three main ways people are trying to fight back against surveillance and protect privacy. Each approach has its own strengths and problems, but they all matter.</p>

            <!-- Strategy 1: Legislative -->
            <div class="strategy">
                <div class="strategy-header">
                    <span class="strategy-number">01</span>
                    <h3>Legislative & Regulatory Frameworks</h3>
                    <span class="strategy-tag legislative">Policy</span>
                </div>
                <div class="strategy-content">
                    <p class="strategy-description">Governments around the world are starting to pass laws that actually give people rights over their data and hold companies accountable when they mess up.</p>
                    
                    <div class="strategy-details">
                        <div class="detail-column">
                            <h4>Key Examples</h4>
                            <ul>
                                <li><strong>EU GDPR (2018):</strong> Established rights to access, rectification, erasure, and data portability with strong enforcement mechanisms</li>
                                <li><strong>California CCPA/CPRA:</strong> Provided Americans rights to know, delete, and opt out of data sales</li>
                                <li><strong>Proposed Federal Legislation:</strong> American Data Privacy and Protection Act aims for national standards</li>
                            </ul>
                        </div>
                        <div class="detail-column">
                            <h4>Evidence of Success</h4>
                            <ul>
                                <li>‚Ç¨5.65 billion in GDPR fines issued through early 2025, demonstrating enforcement capability (CMS Law, 2025)</li>
                                <li>72% of Europeans have heard of GDPR, with 40% knowing what it is (European Commission, 2024)</li>
                                <li>8-26% reduction in tracking cookies on EU websites after GDPR implementation (Degeling et al., 2019)</li>
                            </ul>
                        </div>
                    </div>

                    <div class="evaluation">
                        <div class="eval-success">
                            <h5>‚úì Strengths</h5>
                            <p>These laws actually give people enforceable rights, show that governments can regulate Big Tech, and force companies to be more transparent about what they're doing with data. GDPR especially has set a standard that other countries are starting to follow</p>
                        </div>
                        <div class="eval-limitations">
                            <h5>‚úó Limitations</h5>
                            <p>All those consent pop-ups get annoying and people stop paying attention. Compliance is expensive, which helps big corporations more than small ones. Enforcement isn't consistent across borders. Plus, these laws don't really challenge the underlying business model ‚Äî they just put some guardrails on it. And they still put a lot of responsibility on individuals to protect themselves</p>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Strategy 2: Technical Solutions -->
            <div class="strategy">
                <div class="strategy-header">
                    <span class="strategy-number">02</span>
                    <h3>Privacy-Enhancing Technologies (PETs)</h3>
                    <span class="strategy-tag technical">Technology</span>
                </div>
                <div class="strategy-content">
                    <p class="strategy-description">These are technical tools that let you actually use data and technology while still protecting people's privacy. Things like encryption, anonymization, and building privacy protections right into how systems work from the start.</p>
                    
                    <div class="strategy-details">
                        <div class="detail-column">
                            <h4>Key Examples</h4>
                            <ul>
                                <li><strong>End-to-End Encryption:</strong> Signal, WhatsApp encryption prevent intermediary access to communications</li>
                                <li><strong>Differential Privacy:</strong> Apple's approach adds mathematical noise to protect individual data while enabling aggregate analysis</li>
                                <li><strong>Anonymization Tools:</strong> Tor Browser, VPNs, privacy-focused browsers like Brave</li>
                                <li><strong>Privacy-by-Design:</strong> Building privacy protections into systems from inception</li>
                            </ul>
                        </div>
                        <div class="detail-column">
                            <h4>Evidence of Success</h4>
                            <ul>
                                <li>Signal surged to 40+ million users following privacy concerns about mainstream platforms</li>
                                <li>Tor Network enables journalists and activists to communicate safely in authoritarian regimes</li>
                                <li>Differential privacy allows Apple to gather insights while providing mathematically verifiable privacy guarantees</li>
                            </ul>
                        </div>
                    </div>

                    <div class="evaluation">
                        <div class="eval-success">
                            <h5>‚úì Strengths</h5>
                            <p>These tools give people real, tangible ways to protect themselves. Privacy gets built into the technology itself instead of being an afterthought. They enable secure communication for people who really need it, like activists and journalists. And some of them (like differential privacy) are mathematically proven to work</p>
                        </div>
                        <div class="eval-limitations">
                            <h5>‚úó Limitations</h5>
                            <p>A lot of these tools are hard to use if you're not tech-savvy. Some cost money or require newer devices. Because everyone's already on platforms like Facebook, there's pressure to stay there even if they're not private. This creates a new kind of "privacy divide" where only people who can afford protection actually get it</p>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Strategy 3: Education -->
            <div class="strategy">
                <div class="strategy-header">
                    <span class="strategy-number">03</span>
                    <h3>Digital Literacy & Privacy Education</h3>
                    <span class="strategy-tag education">Education</span>
                </div>
                <div class="strategy-content">
                    <p class="strategy-description">This is about teaching people how privacy actually works online and giving them the knowledge to protect themselves. Privacy isn't something you're just born knowing ‚Äî it's a skill you learn (Park, 2013).</p>
                    
                    <div class="strategy-details">
                        <div class="detail-column">
                            <h4>Key Examples</h4>
                            <ul>
                                <li><strong>EFF's Surveillance Self-Defense:</strong> Practical guides for protecting digital privacy</li>
                                <li><strong>Library Initiatives:</strong> "Choose Privacy Every Day" programs at public libraries</li>
                                <li><strong>School Curricula:</strong> Common Sense Media reaches 60% of U.S. K-12 schools with digital citizenship education</li>
                                <li><strong>Community Workshops:</strong> Cryptoparties teach encryption and privacy tools to activists, journalists, and vulnerable populations</li>
                            </ul>
                        </div>
                        <div class="detail-column">
                            <h4>Evidence of Success</h4>
                            <ul>
                                <li>Digital literacy training shows strong predictive power in privacy control behaviors (Park, 2013)</li>
                                <li>Privacy literacy training effective in stimulating children's protective behaviors (Desimpelaere et al., 2020)</li>
                                <li>Media literacy training significantly improves ability to identify misinformation and increases fact-checking (Dewi & Elfiandri, 2024)</li>
                            </ul>
                        </div>
                    </div>

                    <div class="evaluation">
                        <div class="eval-success">
                            <h5>‚úì Strengths</h5>
                            <p>Education builds knowledge that whole communities can share and use. It treats privacy as something you can learn instead of blaming people for not knowing. It helps people organize and push back together. And when more people understand privacy, they start demanding better protections</p>
                        </div>
                        <div class="eval-limitations">
                            <h5>‚úó Limitations</h5>
                            <p>It's hard to reach everyone who needs this education. Sometimes there's so much information that people just shut down and don't know where to start. Education can only do so much when people don't have real alternatives to the big platforms. There's also a risk of blaming individuals for not protecting themselves when really the system is the problem. And not everyone has equal access to training</p>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Comparative Analysis -->
            <div class="comparison-box">
                <h3>Comparative Analysis</h3>
                <p><strong>Most Promising Approach:</strong> Honestly, I think we need all three working together. Laws give people actual rights they can enforce. Technical tools make it possible to actually be private in practice. And education helps people understand their rights and push for change. No single approach is going to fix everything, but together they create what security people call "defense in depth."</p>
                <div class="insight">
                    <strong>Critical Limitation:</strong> Here's the thing though ‚Äî all three of these strategies kind of treat privacy as an individual problem when it's really a structural one. They work best when we also push for bigger changes to how surveillance capitalism actually works. That might mean breaking up monopolies, letting workers negotiate over data rights collectively, or finding completely different ways to fund digital services besides selling our information.
                </div>
            </div>
        </div>
    </section>

    <!-- Action Section -->
    <section id="action" class="section action-section">
        <div class="container">
            <h2 class="section-title">Individual Actions & Structural Change</h2>
            <p class="section-intro">As someone who's getting into tech, I've been thinking a lot about what my role is in all of this. I don't see myself as powerless, but I also know I can't fix everything on my own. From a sociological perspective, what I do as an individual is part of bigger structural patterns. My choices matter, but they're also shaped by the systems around me.</p>

            <div class="action-grid">
                <div class="action-card">
                    <div class="action-icon">üíº</div>
                    <h3>Ethical Professional Practice</h3>
                    <ul>
                        <li>Advocate for "privacy by design" principles in technical development</li>
                        <li>Question data collection practices: Is it necessary? Who benefits? What are the risks to vulnerable populations?</li>
                        <li>Refuse to implement dark patterns or deceptive consent mechanisms</li>
                        <li>Document and report unethical data practices through appropriate channels</li>
                    </ul>
                </div>

                <div class="action-card">
                    <div class="action-icon">üì¢</div>
                    <h3>Amplifying Marginalized Voices</h3>
                    <ul>
                        <li>Center privacy needs of vulnerable populations in technical decisions</li>
                        <li>Recognize "universal" solutions often serve privileged defaults while harming marginalized groups</li>
                        <li>Support organizations led by affected communities rather than imposing solutions</li>
                    </ul>
                </div>

                <div class="action-card">
                    <div class="action-icon">üìö</div>
                    <h3>Knowledge Translation</h3>
                    <ul>
                        <li>Make technical privacy information accessible to non-technical audiences</li>
                        <li>Volunteer to teach privacy skills in under-resourced communities</li>
                        <li>Challenge "nothing to hide" rhetoric and privacy fatalism in everyday conversations</li>
                    </ul>
                </div>

                <div class="action-card">
                    <div class="action-icon">ü§ù</div>
                    <h3>Collective Organizing</h3>
                    <ul>
                        <li>Join organizations advocating for structural privacy reforms (EFF, ACLU, Fight for the Future)</li>
                        <li>Participate in public comment periods on privacy regulations</li>
                        <li>Support worker organizing around ethical data practices in tech companies</li>
                    </ul>
                </div>

                <div class="action-card">
                    <div class="action-icon">üõ°Ô∏è</div>
                    <h3>Critical Consumption</h3>
                    <ul>
                        <li>Make informed choices about services and products when feasible</li>
                        <li>Support privacy-respecting alternatives that challenge surveillance capitalism</li>
                        <li>Publicly discuss and critique surveillant practices to denormalize them</li>
                    </ul>
                </div>

                <div class="action-card highlight">
                    <div class="action-icon">üéØ</div>
                    <h3>Acknowledging Limitations</h3>
                    <p><strong>Individual actions alone cannot dismantle surveillance capitalism.</strong> These are structural problems requiring structural solutions. My role is not to "solve" privacy problems individually but to participate in broader social movements, exercise professional responsibility, and contribute to collective efforts that challenge power relationships.</p>
                </div>
            </div>

            <div class="sociological-imagination">
                <blockquote>
                    <p>"The sociological imagination connects 'personal troubles' (my privacy violated) to 'public issues' (surveillance as systemic problem)."</p>
                    <cite>‚Äî C. Wright Mills</cite>
                </blockquote>
                <p>My role is to maintain this connection ‚Äî recognizing how individual experiences reflect broader patterns and how individual choices, aggregated with others and organized collectively, can pressure institutional change and challenge the power structures that enable surveillance capitalism.</p>
            </div>
        </div>
    </section>

    <!-- Resources Section -->
    <section id="resources" class="section resources-section">
        <div class="container">
            <h2 class="section-title">Resources & Further Reading</h2>

            <!-- Featured Interactive Experience -->
            <div class="featured-resource">
                <div class="featured-content">
                    <span class="featured-badge">üé¨ Featured Interactive Experience</span>
                    <h3>Do Not Track - Interactive Documentary</h3>
                    <p>Explore web tracking and surveillance through this award-winning interactive documentary series. Experience firsthand how your data is collected, analyzed, and sold online.</p>
                    <a href="https://episode1.donottrack-doc.com/en/" target="_blank" class="featured-video-link-placeholder">
                        <div class="video-placeholder">
                            <div class="play-button-large">‚ñ∂</div>
                            <p class="click-text">Click to Watch Interactive Documentary</p>
                        </div>
                    </a>
                </div>
            </div>

            <div class="resources-grid">
                <div class="resource-category">
                    <h3>Organizations</h3>
                    <ul class="resource-list">
                        <li><a href="https://www.eff.org" target="_blank">Electronic Frontier Foundation (EFF)</a></li>
                        <li><a href="https://www.aclu.org" target="_blank">American Civil Liberties Union (ACLU)</a></li>
                        <li><a href="https://www.fightforthefuture.org" target="_blank">Fight for the Future</a></li>
                        <li><a href="https://privacyinternational.org" target="_blank">Privacy International</a></li>
                        <li><a href="https://datasociety.net" target="_blank">Data & Society Research Institute</a></li>
                    </ul>
                </div>

                <div class="resource-category">
                    <h3>Privacy Tools</h3>
                    <ul class="resource-list">
                        <li><a href="https://signal.org" target="_blank">Signal</a> - Encrypted messaging</li>
                        <li><a href="https://www.torproject.org" target="_blank">Tor Browser</a> - Anonymous browsing</li>
                        <li><a href="https://duckduckgo.com" target="_blank">DuckDuckGo</a> - Privacy-focused search</li>
                        <li><a href="https://brave.com" target="_blank">Brave Browser</a> - Ad blocking & privacy</li>
                        <li><a href="https://ssd.eff.org" target="_blank">Surveillance Self-Defense</a> - EFF guides</li>
                    </ul>
                </div>

                <div class="resource-category">
                    <h3>Academic Sources</h3>
                    <ul class="resource-list">
                        <li>Zuboff, S. (2019). <em>The Age of Surveillance Capitalism</em></li>
                        <li>Noble, S. U. (2018). <em>Algorithms of Oppression</em></li>
                        <li>Eubanks, V. (2018). <em>Automating Inequality</em></li>
                        <li>Lyon, D. (2003). <em>Surveillance as Social Sorting</em></li>
                        <li>Nissenbaum, H. (2010). <em>Privacy in Context</em></li>
                    </ul>
                </div>

                <div class="resource-category">
                    <h3>Data & Research</h3>
                    <ul class="resource-list">
                        <li><a href="https://www.pewresearch.org" target="_blank">Pew Research Center</a> - Privacy surveys</li>
                        <li><a href="https://www.commonsensemedia.org" target="_blank">Common Sense Media</a> - Digital citizenship</li>
                        <li><a href="https://epic.org" target="_blank">EPIC</a> - Privacy news & policy</li>
                    </ul>
                </div>
            </div>

            <!-- References -->
            <div class="references">
                <h3>References</h3>
                <div class="reference-list">
                    <p>Biddle, S. (2020, October 30). DHS authorities are buying moment-by-moment geolocation cellphone data to track people. <em>BuzzFeed News</em>. https://www.buzzfeednews.com/article/hamedaleaziz/ice-dhs-cell-phone-data-tracking-geolocation</p>
                    
                    <p>Buolamwini, J., & Gebru, T. (2018). Gender shades: Intersectional accuracy disparities in commercial gender classification. <em>Proceedings of Machine Learning Research</em>, 81, 77-91.</p>
                    
                    <p>Cinnamon, J. (2017). Social injustice in surveillance capitalism. <em>Surveillance & Society</em>, 15(5), 609-625.</p>

                    <p>CMS Law. (2025). GDPR enforcement tracker report 2024/2025. Retrieved from https://cms.law/en/int/publication/gdpr-enforcement-tracker-report</p>

                    <p>Degeling, M., Utz, C., Lentzsch, C., Hosseini, H., Schaub, F., & Holz, T. (2019). We value your privacy... now take some cookies: Measuring the GDPR's impact on web privacy. In <em>Network and Distributed System Security Symposium (NDSS)</em>.</p>

                    <p>Desimpelaere, L., Hudders, L., & Van de Sompel, D. (2020). Knowledge as a strategy for privacy protection: How a privacy literacy training affects children's online disclosure behavior. <em>Computers in Human Behavior</em>, 110, 106382.</p>

                    <p>Dewi, A., & Elfiandri, E. (2024). Media literacy training effectiveness in reducing misinformation susceptibility. <em>Journal of Communication Studies</em>.</p>

                    <p>Eubanks, V. (2018). <em>Automating inequality: How high-tech tools profile, police, and punish the poor</em>. St. Martin's Press.</p>

                    <p>European Commission. (2024). <em>Report on the application of Regulation (EU) 2016/679</em>. Brussels: European Commission.</p>

                    <p>Gangadharan, S. P. (2017). The downside of digital inclusion: Expectations and experiences of privacy and surveillance among marginal Internet users. <em>New Media & Society</em>, 19(4), 597-615.</p>

                    <p>Madden, M. (2017). <em>Privacy, security, and digital inequality</em>. Data & Society Research Institute.</p>
                    
                    <p>Park, Y. J. (2013). Digital literacy and privacy behavior online. <em>Communication Research</em>, 40(2), 215-236.</p>
                    
                    <p>Privacy and Civil Liberties Oversight Board. (2014). <em>Report on the Telephone Records Program Conducted under Section 215 of the USA PATRIOT Act</em>. Washington, DC: Government Printing Office.</p>

                    <p>Richards, N. M., & Hartzog, W. (2019). The pathologies of digital consent. <em>Washington University Law Review</em>, 96(6), 1461-1503.</p>

                    <p>Turow, J., Hennessy, M., & Draper, N. A. (2023). Americans cannot consent to companies' use of their data. <em>International Journal of Communication</em>, 17, 2384-2405.</p>
                    
                    <p>Zuboff, S. (2015). Big other: Surveillance capitalism and the prospects of an information civilization. <em>Journal of Information Technology</em>, 30(1), 75-89.</p>

                    <p>Zuboff, S. (2019). <em>The age of surveillance capitalism: The fight for a human future at the new frontier of power</em>. PublicAffairs.</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>&copy; 2025 Digital Privacy Watch. Created for educational purposes.</p>
            <p>A sociological analysis of privacy, consent, and surveillance in the digital age.</p>
        </div>
    </footer>

    <script src="script.js"></script>
</body>
</html>